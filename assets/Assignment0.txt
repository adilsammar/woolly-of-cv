Group 12 

EVA-Woolly

Group Members:

Ammar Adil
Krithiga
Shashwat Dhanraaj
Srikanth Kandarp

——————————————————————————————————————————————————————
Answer 1: 

Channel is a container of similar  or specific kind of information. It can be anything like features, shapes, texture, colour, gradient, curves, edges, patterns, objects  ….
Channel is like a collection of similar type of features extracted by kernel. Kernel stores information about the image in neuron. And collection of neurons is a channel by that kernel.
Channels are can be seen

Kernel comes to use when from an image, if we want to extract some useful features of similar type.
Kernel is like a filter or like a feature extractor, kernel outputs its own channel.
Kernel extracts information and store it in neutron(collection of neutrons is a channel)
Kernels cannot be seen.

——————————————————————————————————————————————————————

Answer 2:

Kernels can be of various sizes i.e. in images we have 2D or 3D kernels of any desired size :5x5 or 100x100. It can be anything. But it is preferable to have kernel size of 3x3 over any other kernel size. The following reasons are:
1. Reaching desired receptive field using 3x3 over big kernels. It reduces parameters significantly,For Eg: A 5x5 Kernel will have 25 neurons(In an image every pixel is a neuron), so to view all the pixels and make a decision if we apply a 5x5 directly it will have 25 parameters which are the weights of neuron where as if we apply two 3x3, the total parameter count will be 9+9 =18. And once we go for bigger networks over complicated images, the difference will be large.
2. Having Odd Kernels allows use to make shapes like triangle more easily which will be tough in even kernels.
3. The GPUs are designed for faster execution of 3x3, hence the processing time is faster


Kernels determines the receptive field of image. 

1st reason:

Performing convolutions essentially mean performing dot product between the kernels and the channels. Here, having a larger kernel size would mean higher computational cost. So we prefer the small kernel size. And 3x3 or 5x5 ends up being the most used kernel size.


2nd reason:
 
Using same kernel size as the channel:
That would mean there will be no convolution operation performed

Having a smaller kernel size would mean missing out the representation on the larger features while having a larger kernel size would mean missing out on the small features. 

Using 1x1 kernel: (Smallest)
Having a kernel size of 1x1 would mean we will end up not having any information on the adjacent/ overlapping pixels
We do not use 2x2 or even-sized kernels since it lacks symmetry around the matrix or the centre point.
3x3 fits in perfectly if we want to have representations even on the smaller features.
		
——————————————————————————————————————————————————————
		
Answer 3:

 99 convolution operation is needed to be performed reach 1x1 from 199x199 
	1.	199x199 >197x197			
	2.	197x197 > 195x195					
	3.	195x195 > 193x193			
	4.	193x193 > 191x191			
	5.	191x191 > 189x189			
	6.	189x189 > 187x187			
	7.	187x187 > 185x185			
	8.	185x185 > 183x183			
	9.	183x183 > 181x181
	10.	181x181 > 179x179
	11.	179x179 > 177x177
	12.	177x177 > 175x175
	13.	175x175 > 173x173
	14.	173x173 > 171x171
	15.	171x171 > 169x169
	16.	169x169 > 167x167
	17.	167x167 > 165x165
	18.	165x165 > 163x163
	19.	163x163 > 161x161
	20.	161x161 > 159x159
	21.	159x159 > 157x157
	22.	157x157 > 155x155
	23.	155x155 > 153x153
	24.	153x153 > 151x151
	25.	151x151 > 149x149
	26.	149x149 > 147x147
	27.	147x147 > 145x145
	28.	145x145 > 143x143
	29.	143x143 > 141x141
	30.	141x141 > 139x139
	31.	139x139 > 137x137
	32.	137x137 > 135x135
	33.	135x135 > 133x133
	34.	133x133 > 131x131
	35.	131x131 > 129x129
	36.	129x129 > 127x127
	37.	127x127 > 125x125
	38.	125x125 > 123x123
	39.	123x123 > 121x121
	40.	121x121 > 119x119
	41.	119x119  > 117x117
	42.	117x117  > 115x115
	43.	115x115 > 113x113
	44.	113x113 > 111x111
	45.	111x111 > 109x109
	46.	109x109 > 107x107
	47.	107x107 > 105x105
	48.	105x105 > 103x103
	49.	103x103 > 101x101
	50.	101x101 > 99x99
	51.	  99x99 > 97x97
	52.	  97x97 > 95x95
	53.	  95x95 > 93x93
	54.	  93x93 > 91x91
	55.	  91x91 > 89x89
	56.	  89x89 > 87x87
	57.	  87x87 > 85x85
	58.	  85x85 > 83x83
	59.	  83x83 > 81x81
	60.	  81x81 > 79x79
	61.	  79x79 > 77x77
	62.	  77x77 > 75x75
	63.	  75x75 > 73x73
	64.	  73x73 > 71x71
	65.	  71x71 > 69x69
	66.	  69x69 > 67x67
	67.	  67x67 > 65x65
	68.	  65x65 > 63x63
	69.	  63x63 > 61x61
	70.	  61x61 > 59x59
	71.	  59x59 > 57x57
	72.	  57x57 > 55x55
	73.	  55x55 > 53x53
	74.	  53x53 > 51x51
	75.	  51x51 > 49x49
	76.	  49x49 > 47x47
	77.	  47x47 > 45x45
	78.	  45x45 > 43x43
	79.	  43x43 > 41x41
	80.	  41x41 > 39x39
	81.	  39x39 > 37x37
	82.	  37x37 > 35x35
	83.	  35x35 > 33x33
	84.	  33x33 > 31x31
	85.	  31x31 > 29x29
	86.	  29x29 > 27x27
	87.	  27x27 > 25x25
	88.	  25x25 > 23x23
	89.	  23x23 > 21x21
	90.	  21x21 > 19x19
	91.	  19x19 > 17x17
	92.	  17x17 > 15x15
	93.	  15x15 > 13x13
	94.	  13x13 > 11x11
	95.	  11x11 > 9x9
	96.	    9x9 > 7x7
	97.	    7x7 > 5x5
	98.	    5x5 > 3x3
	99.	    3x3 > 1x1

——————————————————————————————————————————————————————

Answer 4: 

Kernels values are randomly assigned from a set of random numbers.
We can not have kernel values as 0s or 1s or anything except random for training from scratch. The reasons are as follows:
Kernels are filters which work over the input image and gives out channels as output. If we have all values as 0s, all the convolution operation(Discussed in Part 2) that will take place will be 0. Lets take an Example of Filtering Tea: All 0s means the filter does not have opening to filter the tea from tea leaves. Hence when we pour our tea via that filter we will get nothing.
And if we initialize all kernel values with 1, we will have identical kernels giving same channels as output. The task of the kernel should be to separate, where as if we have same filters it will produce same results. For example: if the filter used to separate tea from tea leaves is open (no nets), it will give the same unfiltered tea back.

——————————————————————————————————————————————————————

Answer 5:
During the training , the base layer neurons store all the pixels of image/input.
In each layer, there is a kernel that extracts features or combines low-level features to give high-level features.
Kernel values are initialized randomly, then, during the training, the model learns and corrects these values based on the features it intends to extract.
1st layer combines pixels to detect edges
2nd layer combines edges to make textures, gradients
3rd layer combines textures to make patterns
4th layer combines patterns to make parts of objects
5th layer combines parts of objects to make objects
Finally, the name/type of object is predicted
